{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets 基本使用"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载在线数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m datasets \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmadao33/new-title-chinese\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m datasets\n",
      "\u001B[1;31mNameError\u001B[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"madao33/new-title-chinese\")\n",
    "datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集合集中的某一项任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolq_dataset = load_dataset(\"super_glue\", \"boolq\")\n",
    "boolq_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照数据集划分进行加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train[10:100]\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train[:50%]\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"madao33/new-title-chinese\", split=[\"train[:50%]\", \"train[50%:]\"])\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_dataset(\"madao33/new-title-chinese\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"][\"title\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"train\"].features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[\"train\"]\n",
    "dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = boolq_dataset[\"train\"]\n",
    "dataset.train_test_split(test_size=0.1, stratify_by_column=\"label\")     # 分类数据集可以按照比例划分"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据选取与过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取\n",
    "datasets[\"train\"].select([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤\n",
    "filter_dataset = datasets[\"train\"].filter(lambda example: \"中国\" in example[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dataset[\"title\"][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每条数据前面拼接上 Perfix:\n",
    "def add_prefix(example):\n",
    "    example[\"title\"] = 'Prefix: ' + example[\"title\"]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    ".map() 的作用是：将你提供的一个函数（在你的例子中是 add_prefix），依次应用到数据集（datasets）中的每一个样本上，然后返回一个经过处理后的新数据集。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 通过map调用\n",
    "prefix_dataset = datasets.map(add_prefix)\n",
    "# 展示前10个title\n",
    "prefix_dataset[\"train\"][:10][\"title\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "def preprocess_function(example, tokenizer=tokenizer):\n",
    "    model_inputs = tokenizer(example[\"content\"], max_length=512, truncation=True)\n",
    "    labels = tokenizer(example[\"title\"], max_length=32, truncation=True)\n",
    "    # label就是title编码的结果\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = datasets.map(preprocess_function)\n",
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = datasets.map(preprocess_function, num_proc=4)\n",
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = datasets.map(preprocess_function, batched=True)\n",
    "processed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = datasets.map(preprocess_function, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "processed_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets.save_to_disk(\"./processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = load_from_disk(\"./processed_data\")\n",
    "processed_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载本地数据集"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接加载文件作为数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"./ChnSentiCorp_htl_all.csv\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_csv(\"./ChnSentiCorp_htl_all.csv\")\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载文件夹内全部文件作为数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=[\"./all_data/ChnSentiCorp_htl_all.csv\", \"./all_data/ChnSentiCorp_htl_all copy.csv\"], split='train')\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过预先加载的其他格式转换加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   label                                             review\n0      1  距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...\n1      1                       商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!\n2      1         早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。\n3      1  宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...\n4      1               CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./ChnSentiCorp_htl_all.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 根据文档参数说明，feature应为Features对象\n",
    "    def from_pandas(\n",
    "        cls,\n",
    "        df: pd.DataFrame,\n",
    "        features: Optional[Features] = None,\n",
    "        info: Optional[DatasetInfo] = None,\n",
    "        split: Optional[NamedSplit] = None,\n",
    "        preserve_index: Optional[bool] = None,\n",
    "    ) -> \"Dataset\":\n",
    "-\n",
    "-\n",
    "- Feature对象如何构建\n",
    "    class Features(dict):       # Feature继承自dict类型\n",
    "        def __init__(*args, **kwargs):      # 任意数量不带关键字参数，任意数量带关键字参数\n",
    "            # self not in the signature to allow passing self as a kwarg\n",
    "            if not args:\n",
    "                raise TypeError(\"descriptor '__init__' of 'Features' object needs an argument\")\n",
    "\n",
    "-\n",
    "-\n",
    "- *args, **kwargs关键字解析\n",
    "def master_function(p1, p2, *args, **kwargs):\n",
    "    print(f\"标准参数 p1: {p1}\")\n",
    "    print(f\"标准参数 p2: {p2}\")\n",
    "    print(f\"位置参数 *args: {args}\")\n",
    "    print(f\"关键字参数 **kwargs: {kwargs}\")\n",
    "\n",
    "master_function(1, 2, 'a', 'b', 'c', status=\"OK\", user_id=123)\n",
    "输出:\n",
    "标准参数 p1: 1\n",
    "标准参数 p2: 2\n",
    "位置参数 *args: ('a', 'b', 'c')   # 不带关键字参数\n",
    "关键字参数 **kwargs: {'status': 'OK', 'user_id': 123}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['label', 'review'],\n    num_rows: 7766\n})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.features import Features\n",
    "\n",
    "\n",
    "# todo:直接将panda处理成dataset格式\n",
    "# 这个Feature得是csv的列名一致才行\n",
    "dataset = Dataset.from_pandas(data,Features({\n",
    "    'label': Value('string'),\n",
    "    'review': Value('string')\n",
    "}))\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text'],\n    num_rows: 2\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List格式的数据需要内嵌{}，明确数据字段\n",
    "data = [{\"text\": \"abc\"}, {\"text\": \"def\"}]\n",
    "# data = [\"abc\", \"def\"]\n",
    "Dataset.from_list(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过自定义加载脚本加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset(\"json\", data_files=\"./cmrc2018_trial.json\", field=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"./load_script.py\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset with DataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"./ChnSentiCorp_htl_all.csv\", split='train')\n",
    "dataset = dataset.filter(lambda x: x[\"review\"] is not None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"review\"], max_length=128, truncation=True)\n",
    "    tokenized_examples[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(process_function, batched=True, remove_columns=dataset.column_names)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_dataset[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(tokenized_dataset, batch_size=4, collate_fn=collator, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for batch in dl:\n",
    "    print(batch[\"input_ids\"].size())\n",
    "    num += 1\n",
    "    if num > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
